* Überall
	* ...I USED DOC-FREQ RIGHT ALL ALONG!!! FUCK
	
* Datasets
	* Allgemein
		* Update die table mit den wörter-die-soundso-oft-vorkommen to reflect nicht term-freq sondern n-docs-containing-it
	* Siddata
		* Histogram über das Dataset mit Anzahl Wörtern, Anzahl Zeichen, Anzahl Wörter Beschreibung allein, ...
        * Average-Description-Length pro eigenschaft in metadata-table
	* Placetypes
		* Datasets-Tabelle mit den key feature sizes für placetypes vervollständigen	

* Algorithm
	* TABELLE which parameter-combis were USED, with optimal ones MARKED for \mainalgos (-> also into yaml!)

	* reference yamls again
	* überall links zu binder!!
	* didn't somebody say that cohen's kappa sucks!?!
	* I may have up to FOUR SECTIONS with the same content
		* Algorithm. Short & Nothing Superflous
		* Implementation Details
		* What-Configs-Are-Available-Where (TABLE??)
		* What-other-things-one-could-have-done-thereandthere





* Results
    * Levensthein-distance-comparison!
	* in results schon schreiben (und tabellen haben!) wie schön nah sich ähnliche dinge schon in BoW-embedding und dimreduced-embedding sind. Neben den ganzen ["asd (tutorial 1)", "asd (tutorial 2)"] auch welche mit ner mindest-levensthein-distance haben, UND nen Plot wie sehr levensthein-distance und nähe im embedding korellieren. UND ne tabelle wie ähnlich nahe-kurse im BoW-embedding und im dimreduced-embedding sind möglicherweise einfach nen kappa score um das ranking der ähnlichsten zu vergleichen


* Appendix
	* Algorihm-als-Sourcecode besser machen