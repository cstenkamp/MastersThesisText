DATASETS:SIDDATA SECTION PRE-TEXT

To write:
	* where does the data come from
	* what size is the data, what is the distribution, ...
	* Preliminary analysis (if I delete all that are shorter than X, it are |Y|..)
	* Does it cluster and look nice?
	* Verteilung der Sprachen
	* Preprocessing in kurzem Fließtext beschreiben - "After throwing out all descriptions shorter than xyz chars, 2323 courses where left. 223 of these were ..."
	* That the type of dataset differs from DESC15 and followups - mainly used movie-dataset consists of concatenated reviews (which means relevant words occur more often!) 
	    (TODO: look/think was die anderen auszeichnet - bei dem placetypedataset ists ja gar kein fließtext sondern direkt ein bag-of-tags)
	Dass mein Datensatz kleiin ist! Bei keinem sonderlichen min-word-per-desc threshold hab ich halt 7588 samples, bei 50 schon nur noch 4123, das ist wirklich little
	Dass auch die Descriptions echt kurz sind! Ich hab rund 8k samples, um das selbe samples-to-threshold verhältnis zu haben wie DESC15 wäre rechnerisch ein wert von 2 bis 25 sinnvoll (wobei man beachten muss das 2 schon richtig kacke ist weil dann die SVM 2 vs 8000 klassifizieren muss and that will never work -> 25 ist minimum), ABER wenn ich dann 25 nehme hab ich nur 2.4k candidates statt the 22k DESC15 aimed at, which also sucks!! --> CONCLUSION: Datensatz scheint zu klein.

* Woher die DDC-Klassifizierung kommt -> SidBERT citen

======================

ich würde SIDDATA immer in caps schreiben wenn du das Projekt meinst, wenn du die software meinst kannst du die ja auch klein introducen bzw die auch mit digital study assistant (DSA) abkürzen

The main goal of this thesis was to create a conceptual space of courses, automatically generated by course descriptions.

For that, a dataset of courses and their descriptions was obtained as export from the Stud.IP system as used at the universities of Osnabrück, Hannover and Bremen.
	* Zum DDC vergleichen Johannes' Paper: https://dl.gi.de/handle/20.500.12116/37023
	* Datensatz selbst...
		* dataset selbst nicht gepublished
		* ein paper ist accepted, not yet published, wo der Prozess beschrieben wird
		* Und sonst würde ich ein weblink Zitat einfügen mit der Referenz auf die BMBF Fördernummer: 16DHB2124
		* und der Weblink darf da auf siddata.de zeigen
		* Woher der originale kam
		* The dataset comes from Johannes' Repo at \url{https://git.siddata.de/jschrumpf/study_behavior_analysis} (requires authentification over UOS!)

Was für columns existieren:
    title, description, language sind klar.
    format, type, source sind meta-infos, die aber nur für wenige gegeben sind.
    subject sind lists of keywords for the course. PERFECT to add to the description AND to automatically take as keyword-candidates!!
    subtitle kann man optional zu den descriptions adden und dann behandeln wie eine descriptions.
    ddc_code, veransltaltungsnummer sind possible targets (!)
    is_hannover, is_bremen, ... sind auch possible targets
    start_semester, url sind for now  komplett egal
    (dabei noch andere Zahlen wie "wie viele Kurse haben überhaupt einen Untertitel", "wie viele der originalen hatten überhaupt ne Beschreibung", ...)

* ....dass der weg von rehct viel pre-preprocessen zu ZERROOO prepreprocessen geführt hat^^

* teile des siddata-datasets wurden mit gtranslate (see appendix xyz)

* Den ganzen "wo ist mein dataset anders als deren" Kram
	* Datensatz ist anders als concatenated-movie-reviews und ich deswegen nicht einfach "je öfter 'scary' desco scarier" machen kann. Wege damit umzugehen sind elaboriert in Section XYZ
	* Da hatte ich schon mehr sehr alte sachen!!!
	* Der Kappa-Score der rankigns vergleicht ist für mich ne kack metric weil ich ebennicht reviews nehme und more-occurences better-candidate heißen -> gucken wie ich stattdessen gute dimensionen und cluster finde (klingt doch so als sei accuracy/f1/... doch wichtig)

* Dass man theoretisch sich den task einfacher machen kann indem man nur die correctly-classified Kurse des fb-classifiers verwendet

* Key Zahlen des Datensatzes mit den gegebenen Vergleichen
	* #words per description,
	* #different words insgesamt
	* TODO MORE, WHAT MORE?!
	* Candidate-Word-Threshold: movies has samples-to-threshold value of 100, placetypes has 35, 20newsgrups has 614, so for 8000 courses any threshold from 2 to 25 seems reasonable => \cite{Derrac2015} say they intentionally kept the number of candidateterms approximate equal (at around 22.000), so to do the same I'd need a threshold of [TODO: optimal value]
	* this stuff: 
		...ist es richtig dass nur 6000 verschiedene Terms >= 25 mal vorkommen?! 6000?!
		=> auch in groß ist mein datensatz ja noch deutlich kleiner als placetypes, die haben immerhin 22k candidates
		--> n-docs: 7596
		--> 1-grams >= 25 times: 5054, 1-5-grams >= 25 times: 6717
		--> unique 1-grams: 106235
		bei placetypes sind es 
		* unique 1-grams: 746180, davon 41320 >= 25 mal und 21833 >= 50 mal (their threshold)
		--> das verhältnis Anzahl Texte zu Länge Texte ist bei mir halt komplett off 


* Andere Key Zahlen: 
	* Fachbereichs-Verteilung MIT PLOT (siehe unten)
	* Sprachen-Verteilung MIT PLOT (siehe unten)

	* Woher sie kommen... 
	* Das count_df einbringen und erklären!
		* ..und dahinter noch was haben was für all die auch noch average length listet (geht erst in running)



* Fachbereichs-classifier
	* The purpose of the Neural Network classifier is to check if it is anyhow possible to extract meaningful information from the descriptions: If it is possible to train a classifier on the data that can reasonably predict a qualitative feature, there is enough structure in the data such that the algorithm I'm about to produce can work.
	* Also, we have a lower bound for useful data: we can just throw away data that cannot be classified!
	* %TODO: train a second classifier on something else and throw away data that gets classified by neither and inspect it
	* (-> 91\% test accuracy)


* warum der Datensatz whack ist / Besonderheiten des datensatzes
	* Die standard-whackities des datensatzes, dass halt viele nur sind "Tutoren sind: Susi Sorglos Willi Wacker", oder "Findet statt in Raum XYZ", 
	* dass alle Sprachkurse die gleichen Beschreibung haben (beispiel. `....len([i for i in descriptions._descriptions if "kompetenzen entwickelt befahigen akademischen berufstypischen" in i.processed_as_string()]) == 25`  ... weil es genau 25 exakt gleiche Beschreibungen gibt, für die Fremdsprachkurse. Deswegen ist up to jede 5-wort-kombination davon ein extracted keyword`) (und das obwohl sie verschiedene Namen haben! merging them doesn't make sense but they are almost equal)


* Woher der Datensatz kommt, dass es ja version 2 des Kurs-Datensatzes von Johannes ist (kommt von: /home/chris/Documents/UNI_neu/Masterarbeit/OTHER/study_behavior_analysis/src/data/course_data/db_dump_new/course_dump_new.csv)

* Meine Pre-Preprocessing Schritte die da ja auch noch gut rumfiltern und rummergen beschreiben

* ausrechnen "um so gut zu sein wie die, müsste der datensatz größe xyz haben"


======================



\begin{figure}[H]
	\centering
	\includegraphics[width=\figwidth]{graphics/figures/courses_language_distribution.png}
	\slcaption{
		\label{fig:courses_language_distribution}
		Distribution of languages of course descriptions.
		%TODO figure if this is the correct amount of preprocessing/throwout to have done
		Of the 21337 courses left after preprocessing, 18,679 were in german language according to the \textit{langdetect} python-package (for details, see \aref{ap:translating}).
		}
\end{figure}


The faculty is easily obtainable from the dataset, as the first one or two digits of the course ID correspond to it. The distribution of the faculties is depicted in figure \ref{fig:faculty_plot}.
\begin{figure}[H]
	\centering
	\includegraphics[width=\figwidth]{graphics/figures/faculty_plot.png}
	\slcaption{
		\label{fig:faculty_plot}
		Distribution of faculties in the courses
		}
\end{figure}


Mir ist bewusst wie viele Kurse auch nach dem bisschen preprocessing was ich mache drin sind deren Beschreibung schlicht lautet “Tutoren: Susi Sorglos und Willi Wacker”


Maximum occurrences:
`term_doc_matrix.index[np.unravel_index(term_doc_matrix.to_numpy().argmax(), term_doc_matrix.to_numpy().shape)[0]], term_doc_matrix.columns[np.unravel_index(term_doc_matrix.to_numpy().argmax(), term_doc_matrix.to_numpy().shape)[1]]`

→ 'Information Systems (Wirtschaftsinformatik) M III: IT-Risikomanagement (Übung)' und 'risk'



* Brauch ich mehr/bessere Daten? Wenn ich nur die 1000 mit den längsten Beschreibungen behalten würde und dann 10 solcher subsets hätte wären halt die Fälle wie "Tutoren sind: Susi Sorglos Willi Wacker" etc raus

* IntroAI für dieses Jahr ist in Stud.IP nen komplett anderer Kurs als für letztes jahr 
		* Tobias hat was gebaut dass die abgleicht! Und er will k-anonymisierung machen. Das vergrößert die Daten sodass es für jedes Datum mindestens k (say 10) Studierende gibt für die etwas zutrifft. Da muss man Daten wegwerfen.
		* Mit meinen Attributen gibt's einige Probleme. Noten gibt's nicht, "allerschweste Datenschutzbedenken". Was studiert wer und in welchem Semester haben wir nur für den Zeitpunkt der Abfrage -> in kombi mit der k-anonymisierung wirds da schwer zu sagen in welchem semester leute was belegt haben