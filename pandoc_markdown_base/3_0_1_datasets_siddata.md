* IntroAI für dieses Jahr ist in Stud.IP nen komplett anderer Kurs als für letztes jahr !!! Thats bad and a reason to look at the data with a grain of salt

The main goal of this thesis was to create a conceptual space of courses, automatically generated by course descriptions. For that, a dataset of courses and their descriptions was obtained as export from the Stud.IP system as used at the universities of Osnabrück, Hannover and Bremen.

#### What's inside & Where the data is from 

* dataset selbst nicht gepublished
    * ein paper ist accepted, not yet published, wo der Prozess beschrieben wird
    * The dataset comes from Johannes' Repo at \url{https://git.siddata.de/jschrumpf/study_behavior_analysis} (requires authentification over UOS!)
* Stud.IP DB for Osna, Bremen & Hannover 
* preliminary MOOC-Crawler? Only tiny amount
    * see Masterarbeit/OTHER/study_behavior_analysis/EducationalResource-2022-01-20.csv
* Inside: Course descriptions
    * Whatever the person that made the course wanted the students to know
    * That it's NOT concatenated and a lot shorter than the datasets of \mainalgos, I cannot assume that more relevant words occur more often
        * So we expect different results (ref evalmetrics???)
        * So we do some things different (ref algorithm sec)
    * TODO: Sample of that in the appendix 
    * Same courses offered multiple times are in there multiple times, sometiems with equal title sometimes without, sometimes with equal veransltaltungsnummer sometimes without
        * IntroAI für dieses Jahr ist in Stud.IP nen komplett anderer Kurs als für letztes jahr. Tobias hat was gebaut dass die abgleicht! Und er will k-anonymisierung machen. Das vergrößert die Daten sodass es für jedes Datum mindestens k (say 10) Studierende gibt für die etwas zutrifft. Da muss man Daten wegwerfen.
        * Proof: data_exploration_Siddata2021 
        * Samples:
            ```
            1.003 	Spez. Soz. III: Wahlforschung (Politische Soziologie)
            1.003 	Erziehung, Bildung und Sozialisation in der modernen Gesellschaft
            1.003 	Infoveranstaltung Master Soziologie
            7.441202 	"Fremdheit" in der Kinder- und Jugendliteratur
            7.441202 	„Mündlichkeit und Schriftlichkeit“
            ```
    * Problems / Besonderheiten / Whackities:: 
        * Often short 
            * \ref{fig:sid_wordsperdesc}
            * Especially Informatik-Department often has links to longer descriptions but there's no straightforward way to follow them
        * Often useless 
            * "Tutoren: Willi Wacker Susi Sorglos"
            * "Findet statt in Raum XYZ"
        * Often repeating 
            * Sprachkurse-Example: Fast alle haben die gleiche description (beispiel. `....len([i for i in descriptions._descriptions if "kompetenzen entwickelt befahigen akademischen berufstypischen" in i.processed_as_string()]) == 25`  ... weil es genau 25 exakt gleiche Beschreibungen gibt, für die Fremdsprachkurse. Deswegen ist up to jede 5-wort-kombination davon ein extracted keyword`) (und das obwohl sie verschiedene Namen haben! merging them doesn't make sense but they are almost equal)

        * Hard and ambiguous to match equal courses!
        * Sample Shitty descriptions: (all from data_exploration_Siddata2021)
            * "BA/MA Hauptmodul"
            * "Bestandteile:Vorlesung + Übung"
            * "Dozent  Dr. Michael Wicke"
            * "Siehe Gruppe A"
            * "s. Modulbeschreibung"
            * "Literatur:wird noch bekannt gegeben"
    * Further exploratory data analysis:
        * seit 2020 gibt's einige mit "!!FÄLLT AUS!! xyz", das macht manchmal das matching zu previosu iterations schwer. Außerdem sind oft die jahrelang-gleich-gebliebenen descriptions um 1-2 sätze die corona ansprehcen ergänzt, further complicating it.
    * Metadata:
        * \ref{tab:siddata_metadata}
        * dass es ja version 2 des Kurs-Datensatzes von Johannes ist
        * What exists:
            ```
            title, description, language sind klar.
            format, type, source sind meta-infos, die aber nur für wenige gegeben sind.
            subject sind lists of keywords for the course. PERFECT to add to the description AND to automatically take as keyword-candidates!!
            subtitle kann man optional zu den descriptions adden und dann behandeln wie eine descriptions.
            ddc_code, veransltaltungsnummer sind possible targets (!)
            is_hannover, is_bremen, ... sind auch possible targets
            start_semester, url sind for now  komplett egal
            (dabei noch andere Zahlen wie "wie viele Kurse haben überhaupt einen Untertitel", "wie viele der originalen hatten überhaupt ne Beschreibung", ...)
            ```




#### Size & Distributions

* Distribution of what's inside, where it's from and its languages 
    * \ref{tab:siddata_metadata}
        * und dahinter noch was haben was für all die auch noch average length listet (geht erst in running)
    * \ref{fig:sid_statistics}
    * Ref the sunburst-plot
    * It was started to be translated using gtranslate such that everything is english but that was dropped with the 2022 data
* Distribution of lengths & words
    * Description-Lengths
        * Verhältnis von #descriptions zu average length
        * \ref{fig:sid_wordsperdesc}
        * Backref \ref{tab:corpussizes}
    * "Preliminary experiments have shown that including short ones led to worse results than excluding, so we excluded."
        * Again \ref{tab:siddata_metadata} (lists number of entities for different word-limits) 
    * That it's REALLY small compared to the others
        * Bei keinem sonderlichen min-word-per-desc threshold hab ich halt XXX samples, bei 50 schon nur noch YYY, das ist wirklich little
        * How I would need to calculate the candidate-word-threshold to have the same one as DESC15 to demonstrate HOW MUCH SMALLER it is
            * how irrelevant the extract-candidtes step of the alrorithm is for my dataset because there are only XXX [was "6k"] unique x-grams anyway so just taking all is the best thing to do anyway
            
            * Candidate-Word-Threshold: movies has samples-to-threshold value of 100, placetypes has 35, 20newsgrups has 614, so for 8000 courses any threshold from 2 to 25 seems reasonable => \cite{Derrac2015} say they intentionally kept the number of candidateterms approximate equal (at around 22.000), so to do the same I'd need a threshold of [TODO: optimal value]
            * REGARDING ORIGINAL DATASET: Dass auch die Descriptions echt kurz sind! Ich hab rund 8k samples, um das selbe samples-to-threshold verhältnis zu haben wie DESC15 wäre rechnerisch ein wert von 2 bis 25 sinnvoll (wobei man beachten muss das 2 schon richtig kacke ist weil dann die SVM 2 vs 8000 klassifizieren muss and that will never work -> 25 ist minimum), ABER wenn ich dann 25 nehme hab ich nur 2.4k candidates statt the 22k DESC15 aimed at, which also sucks!! --> CONCLUSION: Datensatz scheint zu klein.
    * Regarding Candidate Words:
        * TODO: Add number of unique words to the tables!!
        * TODO: ist es richtig dass nur 6000 verschiedene Terms >= 25 mal vorkommen?! 6000?!
            => auch in groß ist mein datensatz ja noch deutlich kleiner als placetypes, die haben immerhin 22k candidates
            --> n-docs: 7596
            --> 1-grams >= 25 times: 5054, 1-5-grams >= 25 times: 6717
            --> unique 1-grams: 106235
            bei placetypes sind es 
            * unique 1-grams: 746180, davon 41320 >= 25 mal und 21833 >= 50 mal (their threshold)
            --> das verhältnis Anzahl Texte zu Länge Texte ist bei mir halt komplett off 
        * ausrechnen "um so gut zu sein wie die, müsste der datensatz größe xyz haben"
    * Datensatz ist anders als concatenated-movie-reviews und ich deswegen nicht einfach "je öfter 'scary' desco scarier" machen kann. Wege damit umzugehen sind elaboriert in Section XYZ

#### How I created it

* 3 different sources that were merged
* My sentwise-merge
* Preliminary analysis 
    * ref data_exploration_Siddata2021 
    * "if I delete all that are shorter than X, it are |Y|"
    * Preprocessing in kurzem Fließtext beschreiben - "After throwing out all descriptions shorter than xyz chars, 2323 courses where left. 223 of these were ..."
* ref Preprocess_Siddata2022_new
* dass der weg von rehct viel pre-preprocessen zu ZERROOO prepreprocessen geführt hat^^
    * Meine Pre-Preprocessing Schritte die da ja auch noch gut rumfiltern und rummergen beschreiben
    * Mir ist bewusst wie viele Kurse auch nach dem bisschen preprocessing was ich mache drin sind deren Beschreibung schlicht lautet “Tutoren: Susi Sorglos und Willi Wacker”

#### What Metadata is there to make prediction-tasks from

* SidBERT & Where DDCs come from (ref similarwork, backgrounds/siddata)
    * 
* Fachbereich (at least for Osna -> size of that subset is  relevant)
    * The faculty is easily obtainable from the dataset, as the first one or two digits of the course ID correspond to it. The distribution of the faculties is depicted in \ref{fig:courses_per_faculty}
    * We'll later look at if it clusters and if Fachbereich can be predicted with ANNs
    * The purpose of the Neural Network classifier is to check if it is anyhow possible to extract meaningful information from the descriptions: If it is possible to train a classifier on the data that can reasonably predict a qualitative feature, there is enough structure in the data such that the algorithm I'm about to produce can work.
	* Also, we have a lower bound for useful data: we can just throw away data that cannot be classified!
    * Dass man theoretisch sich den task einfacher machen kann indem man nur die correctly-classified Kurse des fb-classifiers verwendet, das wirft die oben genannten doofen descriptions raus!!
* I'd like more attributes, but da gibt's einige Probleme. Noten gibt's nicht, "allerschweste Datenschutzbedenken". Was studiert wer und in welchem Semester haben wir nur für den Zeitpunkt der Abfrage -> in kombi mit der k-anonymisierung wirds da schwer zu sagen in welchem semester leute was belegt haben


### Addendums (SORT ME)

* Because of the nature of the dataset I need to do some things differently 
    * I'm not working with reviews or collections-of-tags, that means their "how does this dimension correspond to the count in the reviews" doesn't make sense
        * their algorithm is tailored to this. Take their success-metric for the SVMs splitting the embedding. The more often the word "scary" comes in the concatenated reviews, the more scary the movie is. Sounds legit. The more often the people that took pictures at a particular place mentioned the "nature" of that, the more relevant "nature" is to that place. Also legit. But in the descriptions for courses that involve a lot of mathematics, it is not necessarily the case that the term "mathematics" occurs often. So due to the different nature of my dataset I have to go beyond their algorithm at some points - in this case it is probably the case that different kinds of mathematical terms actually do occur more often, so I'd need calculate these kinds of kappas not based oon a single term but ALREADY on a cluster of terms (... and I can bootstrap my way there, because after I do this I get more words to add to my cluster, rinse and repeat!)