Automatically generated by Mendeley Desktop 1.19.8
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop
Chris' script ran over it.

@article{Alshaikh2019,
abstract = {Conceptual spaces are geometric representations of meaning that were proposed by G{\"{a}}rdenfors (2000). They share many similarities with the vector space embeddings that are commonly used in natural language processing. However, rather than representing entities in a single vector space, conceptual spaces are usually decomposed into several facets, each of which is then modelled as a relatively low-dimensional vector space. Unfortunately, the problem of learning such conceptual spaces has thus far only received limited attention. To address this gap, we analyze how, and to what extent, a given vector space embedding can be decomposed into meaningful facets in an unsupervised fashion. While this problem is highly challenging, we show that useful facets can be discovered by relying on word embeddings to group semantically related features.},
author = {Alshaikh, Rana and Bouraoui, Zied and Schockaert, Steven},
doi = {10.18653/v1/k19-1013},
file = {:home/chris/Documents/Mendeley Desktop/Alshaikh, Bouraoui, Schockaert/Alshaikh, Bouraoui, Schockaert - 2019 - Learning conceptual spaces with disentangled facets.pdf:pdf},
isbn = {9781950737727},
journal = {Proceedings of the 23rd Conference on Computational Natural Language Learning (CoNLL)},
pages = {131--139},
publisher = {Association for Computational Linguistics},
title = {{Learning conceptual spaces with disentangled facets}},
url = {https://aclanthology.org/K19-1013},
year = {2019}
}

@inproceedings{Alshaikh2020,
abstract = {Conceptual spaces are geometric meaning representations in which similar entities are represented by similar vectors. They are widely used in cognitive science, but there has been relatively little work on learning such representations from data. In particular, while standard representation learning methods can be used to induce vector space embeddings from text corpora, these differ from conceptual spaces in two crucial ways. First, the dimensions of a conceptual space correspond to salient semantic features, known as quality dimensions, whereas the dimensions of learned embeddings typically lack any clear interpretation. This has been partially addressed in previous work, which has shown that it is possible to identify directions in learned vector spaces which capture semantic features. Second, conceptual spaces are normally organised into a set of domains, each of which is associated with a separate vector space. In contrast, learned embeddings represent all entities in a single vector space. Our hypothesis in this paper is that such single-space representations are sub-optimal for learning quality dimensions, due to the fact that semantic features are often only relevant to a subset of the entities. We show that this issue can be mitigated by identifying features in a hierarchical fashion. Intuitively, the top-level features split the vector space into domains, allowing us to subsequently identify domain-specific quality dimensions.},
annote = {-Conceptual Spaces have two advantages over vector-spaces: 1) they have interpretable dimensions, 2) they are have sets of domains, each with their own vector-space
-identify features in hierachical fashion. Top-Level features split vector space into domains, and inside that you have domain-specific quality dimensions.
Improvements over Schockhart 2015!},
author = {Alshaikh, Rana and Bouraoui, Zied and Schockaert, Steven},
booktitle = {IJCAI International Joint Conference on Artificial Intelligence},
doi = {10.24963/ijcai.2020/494},
file = {:home/chris/Documents/Mendeley Desktop/Alshaikh, Bouraoui, Schockaert/Alshaikh, Bouraoui, Schockaert - 2020 - Learning Conceptual Spaces with Disentangled Facets.pdf:pdf},
isbn = {9780999241165},
issn = {10450823},
keywords = {Humans and AI: Cognitive Modeling,Machine Learning: Interpretability,Natural Language Processing: Natural Language Proc},
pages = {3573--3579},
title = {{Learning Conceptual Spaces with Disentangled Facets}},
volume = {2021-Janua},
year = {2020}
}

@techreport{Derrac2015,
abstract = {Commonsense reasoning patterns such as interpolation and a fortiori inference have proven useful for dealing with gaps in structured knowledge bases. An important diculty in applying these reasoning patterns in practice is that they rely on fine-grained knowledge of how di↵erent concepts and entities are semantically related. In this paper, we show how the required semantic relations can be learned from a large collection of text documents. To this end, we first induce a conceptual space from the text documents, using multi-dimensional scaling. We then rely on the key insight that the required semantic relations correspond to qualitative spatial relations in this conceptual space. Among others, in an entirely unsupervised way, we identify salient directions in the conceptual space which correspond to interpretable relative properties such as 'more fruity than' (in a space of wines), resulting in a symbolic and interpretable representation of the conceptual space. To evaluate the quality of our semantic relations, we show how they can be exploited by a number of commonsense reasoning based classifiers. We experimentally show that these classifiers can outperform standard approaches, while being able to provide intuitive explanations of classification decisions. A number of crowdsourcing experiments provide further insights into the nature of the extracted semantic relations.},
author = {Derrac, Joaqu{\'{i}}n and Schockaert, Steven},
file = {:home/chris/Documents/Mendeley Desktop/Derrac, Schockaert/Derrac, Schockaert - 2015 - Inducing semantic relations from conceptual spaces a data-driven approach to plausible reasoning.pdf:pdf},
keywords = {Commonsense reasoning Email addresses: jderrac@csc,Conceptual spaces,Dimensionality reduction,Qualitative spatial relations,sschockaert@cscardiffacuk (Steven Schockaert)},
title = {{Inducing semantic relations from conceptual spaces: a data-driven approach to plausible reasoning}},
url = {http://dbpedia.org/About},
year = {2015}
}

@book{Gardenfors2000a,
author = {G{\"{a}}rdenfors, Peter},
doi = {10.7551/mitpress/2076.001.0001},
isbn = {0-262-07199-1},
pages = {318},
publisher = {Bradford Books},
title = {{Conceptual Spaces: The Geometry of Thought}},
year = {2000}
}

@article{Carmel2009,
abstract = {This work investigates cluster labeling enhancement by utilizing Wikipedia, the free on-line encyclopedia. We describe a general framework for cluster labeling that extracts candidate labels from Wikipedia in addition to important terms that are extracted directly from the text. The "labeling quality" of each candidate is then evaluated by several independent judges and the top evaluated candidates are recommended for labeling. Our experimental results reveal that the Wikipedia labels agree with manual labels associated by humans to a cluster, much more than with significant terms that are extracted directly from the text. We show that in most cases even when human's associated label appears in the text, pure statistical methods have difficulty in identifying them as good descriptors. Furthermore, our experiments show that for more than 85{\%} of the clusters in our test collection, the manual label (or an inflection, or a synonym of it) appears in the top five labels recommended by our system. Copyright 2009 ACM.},
author = {Carmel, David and Roitman, Haggai and Zwerdling, Naama},
doi = {10.1145/1571941.1571967},
file = {:home/chris/Documents/Mendeley Desktop/Carmel, Roitman, Zwerdling/Carmel, Roitman, Zwerdling - 2009 - Enhancing cluster labeling using wikipedia.pdf:pdf},
isbn = {9781605584836},
journal = {Proceedings - 32nd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR 2009},
keywords = {Cluster labeling,Wikipedia},
pages = {139--146},
title = {{Enhancing cluster labeling using wikipedia}},
year = {2009}
}

@inproceedings{nothman-etal-2018-stop,
abstract = {Open-source software packages for language processing often include stop word lists. Users may apply them without awareness of their surprising omissions (e.g. {\{}``{\}}hasn{\{}'{\}}t{\{}''{\}} but not {\{}``{\}}hadn{\{}'{\}}t{\{}''{\}}) and inclusions ({\{}``{\}}computer{\{}''{\}}), or their incompatibility with a particular tokenizer. Motivated by issues raised about the Scikit-learn stop list, we investigate variation among and consistency within 52 popular English-language stop lists, and propose strategies for mitigating these issues.},
address = {Melbourne, Australia},
author = {Nothman, Joel and Qin, Hanmin and Yurchak, Roman},
booktitle = {Proceedings of Workshop for {\{}NLP{\}} Open Source Software ({\{}NLP{\}}-{\{}OSS{\}})},
doi = {10.18653/v1/W18-2502},
pages = {7--12},
publisher = {Association for Computational Linguistics},
title = {{Stop Word Lists in Free Open-source Software Packages}},
url = {https://aclanthology.org/W18-2502},
year = {2018}
}

@article{Gardenfors2001,
abstract = {Understanding the process of categorization is a primary research goal in artificial intelligence. The conceptual space framework provides a flexible approach to modeling context-sensitive categorization via a geometrical representation designed for modeling and managing concepts. In this paper we show how algorithms developed in computational geometry, and the Region Connection Calculus can be used to model important aspects of categorization in conceptual spaces. In particular, we demonstrate the feasibility of using existing geometric algorithms to build and manage categories in conceptual spaces, and we show how the Region Connection Calculus can be used to reason about categories and other conceptual regions.},
author = {G{\"{a}}rdenfors, Peter and Williams, Mary Anne},
file = {:home/chris/Documents/Mendeley Desktop/G{\"{a}}rdenfors, Williams/G{\"{a}}rdenfors, Williams - 2001 - Reasoning about categories in conceptual spaces.pdf:pdf},
issn = {10450823},
journal = {IJCAI International Joint Conference on Artificial Intelligence},
pages = {385--392},
title = {{Reasoning about categories in conceptual spaces}},
year = {2001}
}

@inproceedings{maas-EtAl:2011:ACL-HLT2011,
address = {Portland, Oregon, USA},
author = {Maas, Andrew L and Daly, Raymond E and Pham, Peter T and Huang, Dan and Ng, Andrew Y and Potts, Christopher},
booktitle = {Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies},
pages = {142--150},
publisher = {Association for Computational Linguistics},
title = {{Learning Word Vectors for Sentiment Analysis}},
url = {http://www.aclweb.org/anthology/P11-1015},
year = {2011}
}

@article{VISR12,
abstract = {This article introduces the tag genome, a data structure that extends the traditional tagging model to provide enhanced forms of user interaction. Just as a biological genome encodes an organism based on a sequence of genes, the tag genome encodes an item in an information space based on its relationship to a common set of tags. We present a machine learning approach for computing the tag genome, and we evaluate several learning models on a ground truth dataset provided by users. We describe an application of the tag genome called Movie Tuner which enables users to navigate from one item to nearby items along dimensions represented by tags. We present the results of a 7-week field trial of 2,531 users of Movie Tuner and a survey evaluating users subjective experience. Finally, we outline the broader space of applications of the tag genome. {\textcopyright} 2012 ACM.},
annote = {This is source 13 from DESC15, listed there as
"One exception is [13], which proposes a critique based movie recommender. Using a supervised method, their system allows users to specify, for instance, that they want “a film like this one, but grit- tier”. Similarly, [14] proposes a critique based image search engine, based on a supervised method that learns the degree to which visual attributes apply to images, e.g. “I want to buy shoes like these, but shinier”"},
author = {Vig, Jesse and Sen, Shilad and Riedl, John},
doi = {10.1145/2362394.2362395},
file = {:home/chris/Documents/Mendeley Desktop/Vig, Sen, Riedl/Vig, Sen, Riedl - 2012 - The tag genome Encoding community knowledge to support novel interaction.pdf:pdf},
issn = {21606463},
journal = {ACM Transactions on Interactive Intelligent Systems},
keywords = {Tagging,conversational recommenders,data mining,information retrieval,machine learning,recommender systems},
number = {3},
title = {{The tag genome: Encoding community knowledge to support novel interaction}},
volume = {2},
year = {2012}
}

@inproceedings{Ager2018,
abstract = {In this paper we consider semantic spaces consisting of objects from some particular domain (e.g. IMDB movie reviews). Various authors have observed that such semantic spaces often model salient features (e.g. how scary a movie is) as directions. These feature directions allow us to rank objects according to how much they have the corresponding feature, and can thus play an important role in interpretable classifiers, recommendation systems, or entity-oriented search engines, among others. Methods for learning semantic spaces, however, are mostly aimed at modelling similarity. In this paper, we argue that there is an inherent trade-off between capturing similarity and faithfully modelling features as directions. Following this observation, we propose a simple method to fine-tune existing semantic spaces, with the aim of improving the quality of their feature directions. Crucially, our method is fully unsupervised, requiring only a bag-of-words representation of the objects as input.},
address = {Stroudsburg, PA, USA},
author = {Ager, Thomas and Ku{\v{z}}elka, Ondřej and Schockaert, Steven},
booktitle = {CoNLL 2018 - 22nd Conference on Computational Natural Language Learning, Proceedings},
doi = {10.18653/v1/k18-1051},
file = {:home/chris/Documents/Mendeley Desktop/Ager, Ku{\v{z}}elka, Schockaert/Ager, Ku{\v{z}}elka, Schockaert - 2018 - Modelling salient features as directions in fine-tuned semantic spaces.pdf:pdf},
isbn = {9781948087728},
pages = {530--540},
publisher = {Association for Computational Linguistics},
title = {{Modelling salient features as directions in fine-tuned semantic spaces}},
url = {http://aclweb.org/anthology/K18-1051},
year = {2018}
}

@article{Cohn1997,
abstract = {This paper surveys the work of the qualitative spatial reasoning group at the University of Leeds. The group has developed a number of logical calculi for representing and reasoning with qualitative spatial relations over regions. We motivate the use of regions as the primary spatial entity and show how a rich language can be built up from surprisingly few primitives. This language can distinguish between convex and a variety of concave shapes and there is also an extension which handles regions with uncertain boundaries. We also present a variety of reasoning techniques, both for static and dynamic situations. A number of possible application areas are briefly mentioned.},
annote = {Gelesen: Kapitel 1},
author = {Cohn, Anthony G. and Bennett, Brandon and Gooday, John and Gotts, Nicholas Mark},
doi = {10.1023/A:1009712514511},
file = {:home/chris/Documents/Mendeley Desktop/Cohn et al/Cohn et al. - 1997 - Qualitative Spatial Representation and Reasoning with the Region Connection Calculus.pdf:pdf},
issn = {13846175},
journal = {GeoInformatica},
keywords = {Qualitative spatial reasoning,Shape,Spatial logics,Topology,Vague boundaries},
number = {3},
pages = {275--316},
title = {{Qualitative Spatial Representation and Reasoning with the Region Connection Calculus}},
volume = {1},
year = {1997}
}

@inproceedings{loper-bird-2002-nltk,
address = {Philadelphia, Pennsylvania, USA},
author = {Loper, Edward and Bird, Steven},
booktitle = {Proceedings of the {\{}ACL{\}}-02 Workshop on Effective Tools and Methodologies for Teaching Natural Language Processing and Computational Linguistics},
doi = {10.3115/1118108.1118117},
pages = {63--70},
publisher = {Association for Computational Linguistics},
title = {{{\{}NLTK{\}} : The Natural Language Toolkit}},
url = {https://aclanthology.org/W02-0109},
year = {2002}
}

@article{Gardenfors2004,
abstract = {The Semantic Web is not semantic. It is good for syllogistic reasoning, but there is much more to semantics than syllogisms. I argue that the current Semantic Web is too dependent on symbolic representations of information structures, which limits its representational capacity. As a remedy, I propose conceptual spaces as a tool for expressing more of the semantics. Conceptual spaces are built up from quality dimensions that have geometric or topological structures. With the aid of the dimensions, similarities between objects can easily be represented and it is argued that similarity is a central aspect of semantic content. By sorting the dimensions into domains, I define properties and concepts and show how prototype effects of concepts can be treated with the aid of conceptual spaces. I present an outline of how one can reconstruct most of the taxonomies and other meta-data that are explicitly coded in the current Semantic Web and argue that inference engines on the symbolic level will become largely superfluous. As an example of the semantic power of conceptual spaces, I show how concept combinations can be analysed in a much richer and more accurate way than in the classical logical approach.},
annote = {First description of CS: "Conceptual spaces are built up from quality dimensions that have geometric or topological structures. With the aid of the dimensions, similarities between objects can easily be represented and it is argued that similarity is a central aspect of semantic content. By sorting the dimensions into domains, I define properties and concepts and show how prototype effects of concepts can be treated with the aid of conceptual spaces."},
author = {G{\"{a}}rdenfors, P},
file = {:home/chris/Documents/Mendeley Desktop/G{\"{a}}rdenfors/G{\"{a}}rdenfors - 2004 - How to make the semantic web more semantic.pdf:pdf},
journal = {Formal Ontology in Information Systems. IOS Press},
pages = {17--36},
title = {{How to make the semantic web more semantic}},
url = {http://yaxu.org/tmp/Gardenfors04.pdf},
year = {2004}
}

@article{Molder2021a,
abstract = {Data analysis often entails a multitude of heterogeneous steps, from the application of various command line tools to the usage of scripting languages like R or Python for the generation of plots and tables. It is widely recognized that data analyses should ideally be conducted in a reproducible way. Reproducibility enables technical validation and regeneration of results on the original or even new data. However, reproducibility alone is by no means sufficient to deliver an analysis that is of lasting impact (i.e., sustainable) for the field, or even just one research group. We postulate that it is equally important to ensure adaptability and transparency. The former describes the ability to modify the analysis to answer extended or slightly different research questions. The latter describes the ability to understand the analysis in order to judge whether it is not only technically, but methodologically valid.Here, we analyze the properties needed for a data analysis to become reproducible, adaptable, and transparent. We show how the popular workflow management system Snakemake can be used to guarantee this, and how it enables an ergonomic, combined, unified representation of all steps involved in data analysis, ranging from raw data processing, to quality control and fine-grained, interactive exploration and plotting of final results.},
author = {M{\"{o}}lder, Felix and Jablonski, Kim Philipp and Letcher, Brice and Hall, Michael B. and Tomkins-Tinch, Christopher H. and Sochat, Vanessa and Forster, Jan and Lee, Soohyun and Twardziok, Sven O. and Kanitz, Alexander and Wilm, Andreas and Holtgrewe, Manuel and Rahmann, Sven and Nahnsen, Sven and K{\"{o}}ster, Johannes},
doi = {10.12688/F1000RESEARCH.29032.1},
file = {:home/chris/Documents/Mendeley Desktop/M{\"{o}}lder et al/M{\"{o}}lder et al. - 2021 - Sustainable data analysis with Snakemake(3).pdf:pdf},
issn = {2046-1402},
journal = {F1000Research},
keywords = {Lee S: Methodology, Software,Letcher B: Methodology, Software, Writing-Review {\&},Nahnsen S: Conceptualization,Rahmann S: Supervision, Writing-Review {\&} Editing,Sochat V: Methodology, Software, Writing-Review {\&},Tomkins-Tinch CH: Methodology, Software, Writing-R,Twardziok SO: Methodology, Software,Wilm A: Methodology, Software, Writing-Review {\&} Ed,adaptability,data analysis,reproducibility,scalability,sustainability,transparency,workflow management},
month = {jan},
pages = {33},
publisher = {F1000 Research Ltd},
title = {{Sustainable data analysis with Snakemake}},
url = {https://f1000research.com/articles/10-33},
volume = {10},
year = {2021}
}

@misc{nakatani2010langdetect,
author = {Shuyo, Nakatani},
title = {{Language Detection Library for Java}},
url = {http://code.google.com/p/language-detection/},
year = {2010},
howpublished = {\url{http://code.google.com/p/language-detection/}}
}
